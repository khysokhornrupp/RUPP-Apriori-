{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import numpy_indexed as npi\n",
    "from itertools import combinations, product\n",
    "from functools import reduce\n",
    "from collections.abc import Iterable\n",
    "import math\n",
    "# use for vertify\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>StockCode</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "StockCode  A  B  C  D\n",
       "InvoiceNo            \n",
       "1          1  1  1  0\n",
       "2          0  1  1  1\n",
       "3          1  0  1  1\n",
       "4          1  1  0  0"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dataset_path = '/home/sokhorn/sokhorn/dataSet/data/sample_data_set.csv'\n",
    "sample_dataset = pd.read_csv(\n",
    "    testing_dataset_path, sep=',', usecols=[\n",
    "        'InvoiceNo',\n",
    "        'StockCode',\n",
    "        'Quantity'\n",
    "    ])\n",
    "sample_dataset\n",
    "item_sets = (\n",
    "    sample_dataset.groupby(['InvoiceNo', 'StockCode', ])['Quantity']\n",
    "    .sum().unstack().reset_index().fillna(0)\n",
    "    .set_index(\"InvoiceNo\")\n",
    ")\n",
    "# item_sets = item_sets.iloc[:, :10]\n",
    "item_sets = item_sets.head(1000)\n",
    "item_sets = item_sets.applymap(lambda x: 1 if x > 0 else 0)\n",
    "item_sets.reindex(sorted(item_sets.columns), axis=1)\n",
    "item_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating RC count for each row of our data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RC count generation \n",
    "itemset_reduct, rc_values =  npi.count(item_sets.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc(item_np):\n",
    "    np_hash = {}\n",
    "    item_rc = []\n",
    "    for item in item_np:\n",
    "        key = \" \".join(map(str, item))\n",
    "        if np_hash.get(key):\n",
    "            np_hash[key] += 1\n",
    "        else:\n",
    "            np_hash[key] = 1\n",
    "\n",
    "    for item in np_hash:\n",
    "        values = list(map(int,  item.split()))\n",
    "        values.append(np_hash[item])\n",
    "        item_rc.append(values)\n",
    "    return item_rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  1  1  1  0\n",
       "1  0  1  1  1\n",
       "2  1  0  1  1\n",
       "3  1  1  0  0"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RC counr and tranction after reduce\n",
    "rc_np = np.array(rc(item_sets.values))\n",
    "df_rc = pd.DataFrame(rc_np)\n",
    "columns = list(item_sets.columns)\n",
    "columns.append(\"RC\")\n",
    "df_rc.set_axis(columns, inplace=True, axis=1)\n",
    "RC = df_rc['RC']\n",
    "df_rc.drop(['RC'], axis=1, inplace=True)\n",
    "df_rc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Count \n",
    "# reduce(function, input)\n",
    "def support_k_itemst(k_itemst):\n",
    "    s = 0\n",
    "    for i in range(len(k_itemst)):\n",
    "        s += reduce(lambda a, b: a & b, k_itemst[i] & RC[i])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_appriori(k_itemset, item_sets = df_rc):\n",
    "    mask = (k_itemset == 1).all(axis=1) # get all row which value are equal to 1 \n",
    "    return len(item_sets[mask])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating 1 itemse base on support count of row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = {}\n",
    "L = {}\n",
    "k_items = []\n",
    "Discard = {}\n",
    "itemset_size = 1\n",
    "min_support = 0.5\n",
    "Discard.update({itemset_size: []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove every column which it support count are less than user defind support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove each column who support count are less than min_support for 1 itemsets\n",
    "rc_1_itemset = df_rc.sum(axis=0)\n",
    "# remove all column which sum of row are ness than user defind support threshold\n",
    "cut_our_cols = rc_1_itemset.loc[lambda x: x < min_support].index\n",
    "# cut our every itemset which are sum of each row are less than user defind support\n",
    "df_rc.drop(labels=cut_our_cols, axis=1, inplace=True)\n",
    "# updpate the first item set which are in frequent \n",
    "Discard.update({itemset_size: cut_our_cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: Index([], dtype='object')}"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent 1 itemsets\n",
    "C.update({itemset_size: np.reshape(list(df_rc.columns), (-1, 1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import itertools\n",
    "\n",
    "\n",
    "def join_step(itemsets: typing.List[tuple]):\n",
    "    i = 0\n",
    "\n",
    "    while i < len(itemsets):\n",
    "\n",
    "        skip = 1\n",
    "\n",
    "        *itemset_first, itemset_last = itemsets[i]\n",
    "\n",
    "        tail_items = [itemset_last]\n",
    "        tail_items_append = tail_items.append\n",
    "\n",
    "        for j in range(i + 1, len(itemsets)):\n",
    "\n",
    "            *itemset_n_first, itemset_n_last = itemsets[j]\n",
    "\n",
    "            if itemset_first == itemset_n_first:  # k - 1, item are identical\n",
    "                tail_items_append(itemset_n_last)\n",
    "                skip += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        itemset_first_tuple = tuple(itemset_first)\n",
    "        for a, b in sorted(itertools.combinations(tail_items, 2)):\n",
    "            yield list(itemset_first_tuple + (a,) + (b,))\n",
    "\n",
    "        i += skip\n",
    "\n",
    "\n",
    "def prune_step(itemsets: typing.Iterable[tuple], possible_itemsets: typing.List[tuple]):\n",
    "    itemsets = [\n",
    "        np.unique(subarr) for subarr in itemsets\n",
    "    ]\n",
    "    for possible_itemset in possible_itemsets:\n",
    "        for i in range(len(possible_itemset) - 2):\n",
    "            removed = possible_itemset[:i] + possible_itemset[i + 1:]\n",
    "            if (np.array(removed) not in np.array(itemsets)):\n",
    "                break\n",
    "            else:\n",
    "                yield possible_itemset\n",
    "            yield possible_itemset\n",
    "\n",
    "\n",
    "def apriori_gen(item_sets):\n",
    "    posible_extenstion = join_step(item_sets)\n",
    "    yield from prune_step(item_sets, posible_extenstion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def candidate_generation(Lk):\n",
    "#     try:\n",
    "#         k = len(Lk)\n",
    "#         k_1_item = len(Lk[0]) - 1\n",
    "#         for i in range(k):\n",
    "#             L1 = list(Lk[i])[-k_1_item::]\n",
    "#             for j in range(i + 1, k):\n",
    "#                 L2 = list(Lk[j])[:k_1_item:]\n",
    "#                 if L1 == L2:\n",
    "#                     yield list(np.union1d(Lk[i], Lk[j]))\n",
    "#                     # test next item the same or not, if no break this loop\n",
    "#                     if(j + 1 < k):\n",
    "#                         if((L1 != list(Lk[j + 1])[:k_1_item:])):\n",
    "#                             break\n",
    "\n",
    "#     except IndexError as err:\n",
    "#         print(f\"Error with {err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent(itemesets, min_support, prev_discard):\n",
    "    L = []\n",
    "    support_count = []\n",
    "    new_discard = []\n",
    "    k = len(prev_discard)\n",
    "    for i in range(len(itemesets)):\n",
    "        discard_before = False\n",
    "        result = itemesets[i]\n",
    "\n",
    "        # if result in prev_discard than break this loop\n",
    "        if k > 0:\n",
    "            for it in prev_discard[k]:\n",
    "                if set(it).issubset(set(result)):\n",
    "                    discard_before = True\n",
    "                    break\n",
    "        \n",
    "        if not discard_before:\n",
    "            # print(f'item {mergeKItemIntoOne(item)}')\n",
    "            count = support_k_itemst(df_rc[result].values)\n",
    "            if count >= min_support:\n",
    "                L.append(result)\n",
    "                support_count.append(count)\n",
    "            else:\n",
    "                new_discard.append(result)\n",
    "    return L, support_count, new_discard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frequent(itemesets, min_support, prev_discard):\n",
    "#     k = len(prev_discard)\n",
    "#     for i in range(len(itemesets)):\n",
    "#         discard_before = False\n",
    "#         result = itemesets[i]\n",
    "\n",
    "#         # if result in prev_discard than break this loop\n",
    "#         if k > 0:\n",
    "#             for it in prev_discard[k]:\n",
    "#                 if set(it).issubset(set(result)):\n",
    "#                     discard_before = True\n",
    "#                     break\n",
    "\n",
    "#         if not discard_before:\n",
    "#             # print(f'item {mergeKItemIntoOne(item)}')\n",
    "#             count = support_appriori(df_rc[result])\n",
    "#             status = True\n",
    "#             if count >= min_support:\n",
    "#                 status = False\n",
    "#             else:\n",
    "#                 status = True\n",
    "#             yield result, count, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_count = {}\n",
    "f, supp, new_discard, = get_frequent(C[itemset_size], min_support, Discard)\n",
    "\n",
    "Discard.update({itemset_size: new_discard})\n",
    "L.update({itemset_size: f})\n",
    "support_count.update({itemset_size: supp})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 = np.array(C[1]).flatten()\n",
    "\n",
    "\n",
    "# def candidate_generation_1(Lk):\n",
    "#     try:\n",
    "#         k = len(Lk)\n",
    "#         for i in range(k):\n",
    "#             for j in range(i + 1, k):\n",
    "#                 yield list(np.union1d(Lk[i], Lk[j]))\n",
    "#     except IndexError as err:\n",
    "#         print(f\"Error with {err}\")\n",
    "\n",
    "\n",
    "# C.update({k: list(candidate_generation_1(L[k - 1]))})\n",
    "# f, supp, new_discard = filter_item(get_frequent(C[k], min_support, Discard))\n",
    "# L.update({k: f})\n",
    "# Discard.update({k: new_discard})\n",
    "# support_count.update({k: supp})\n",
    "\n",
    "\n",
    "# k += 1\n",
    "# c_k = list(candidate_generation(L[k - 1]))\n",
    "# f, supp, new_discard = filter_item(\n",
    "#     get_frequent(c_k, min_support, Discard))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_item_set_gen():\n",
    "    k = itemset_size + 1\n",
    "    while True:\n",
    "        try:\n",
    "            C.update(\n",
    "                {\n",
    "                    k: list(join_step(L[k - 1]))\n",
    "                }\n",
    "            )\n",
    "            f, supp, new_discard = get_frequent(C[k], min_support, Discard)\n",
    "            L.update({k: f})\n",
    "            Discard.update({k: new_discard})\n",
    "            support_count.update({k: supp})\n",
    "            if(len(L[k]) == 0):\n",
    "                break\n",
    "            k += 1\n",
    "        except ValueError as err:\n",
    "            print(f\"Hello, there some error with {err}\")\n",
    "            break\n",
    "    return C, support_count, Discard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, s, d = frequent_item_set_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_loop_array():\n",
    "    for i in range(10):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "r = range(1, 151)\n",
    "dt = []\n",
    "for i in r:\n",
    "    frequent_item_set_gen()\n",
    "    dt.append(timeit.default_timer()-start_time)\n",
    "plt.plot(r, dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
