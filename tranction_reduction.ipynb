{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tranction_reduction import TranctionReduction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_indexed as npi\n",
    "from itertools import combinations, product\n",
    "from functools import reduce\n",
    "from collections.abc import Iterable\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import apriori\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>StockCode</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "StockCode  A  B  C  D\n",
       "InvoiceNo            \n",
       "1          1  1  1  0\n",
       "2          0  1  1  1\n",
       "3          1  0  1  1\n",
       "4          1  1  0  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_dataset_path = \"/home/sokhorn/sokhorn/dataSet/data/Online Retail.csv\"\n",
    "testing_dataset_path = '/home/sokhorn/sokhorn/dataSet/data/sample_data_set.csv'\n",
    "# tranction_reduction_itemsets = '/home/sokhorn/sokhorn/dataSet/data/sample_tranc_red.csv'\n",
    "sample_dataset = pd.read_csv(\n",
    "    testing_dataset_path, sep=',', usecols=[\n",
    "        'InvoiceNo',\n",
    "        'StockCode',\n",
    "        'Quantity',\n",
    "    ])  \n",
    "\n",
    "# item_sets = (\n",
    "#     sample_dataset[sample_dataset['Country'] == 'France'].groupby(['InvoiceNo', 'StockCode', ])['Quantity']\n",
    "#     .sum().unstack().reset_index().fillna(0)\n",
    "#     .set_index(\"InvoiceNo\")\n",
    "# )\n",
    "item_sets = (\n",
    "    sample_dataset.groupby(['InvoiceNo', 'StockCode', ])['Quantity']\n",
    "    .sum().unstack().reset_index().fillna(0)\n",
    "    .set_index(\"InvoiceNo\")\n",
    ")\n",
    "item_sets = item_sets.applymap(lambda x: 1 if x > 0 else 0)\n",
    "item_sets.reindex(sorted(item_sets.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranditonal Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(B, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(D, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(B, D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(C, B, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(C, D, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(C, B, D)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support   itemsets\n",
       "0      0.75        (A)\n",
       "1      0.75        (B)\n",
       "2      0.75        (C)\n",
       "3      0.50        (D)\n",
       "4      0.50     (B, A)\n",
       "5      0.50     (C, A)\n",
       "6      0.25     (D, A)\n",
       "7      0.50     (C, B)\n",
       "8      0.25     (B, D)\n",
       "9      0.50     (C, D)\n",
       "10     0.25  (C, B, A)\n",
       "11     0.25  (C, D, A)\n",
       "12     0.25  (C, B, D)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sebastian Raschka 2014-2020\n",
    "# myxtend Machine Learning Library Extensions\n",
    "# Author: Sebastian Raschka <sebastianraschka.com>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def generate_new_combinations(old_combinations):\n",
    "    items_types_in_previous_step = np.unique(old_combinations.flatten())\n",
    "    for old_combination in old_combinations:\n",
    "        max_combination = old_combination[-1]  # get a single item in the last\n",
    "        mask = items_types_in_previous_step > max_combination\n",
    "        valid_items = items_types_in_previous_step[mask]\n",
    "        old_tuple = tuple(old_combination)\n",
    "        for item in valid_items:\n",
    "\n",
    "            yield from old_tuple\n",
    "            yield item\n",
    "\n",
    "\n",
    "def generate_new_combinations_low_memory(old_combinations, X, min_support,\n",
    "                                         is_sparse):\n",
    "\n",
    "    items_types_in_previous_step = np.unique(old_combinations.flatten())\n",
    "    rows_count = X.shape[0]\n",
    "    threshold = min_support * rows_count\n",
    "    for old_combination in old_combinations:\n",
    "        max_combination = old_combination[-1]\n",
    "        mask = items_types_in_previous_step > max_combination\n",
    "        valid_items = items_types_in_previous_step[mask]\n",
    "        old_tuple = tuple(old_combination)\n",
    "        if is_sparse:\n",
    "            mask_rows = X[:, old_tuple].toarray().all(axis=1)\n",
    "            X_cols = X[:, valid_items].toarray()\n",
    "            supports = X_cols[mask_rows].sum(axis=0)\n",
    "        else:\n",
    "            mask_rows = X[:, old_tuple].all(axis=1)\n",
    "            supports = X[mask_rows][:, valid_items].sum(axis=0)\n",
    "        valid_indices = (supports >= threshold).nonzero()[0]\n",
    "        for index in valid_indices:\n",
    "            yield supports[index]\n",
    "            yield from old_tuple\n",
    "            yield valid_items[index]\n",
    "\n",
    "\n",
    "def apriori(df, min_support=0.5, use_colnames=False, max_len=None, verbose=0,\n",
    "            low_memory=False):\n",
    "\n",
    "    def _support(_x, _n_rows, _is_sparse):\n",
    "\n",
    "        out = (np.sum(_x, axis=0) / _n_rows)\n",
    "        return np.array(out).reshape(-1)\n",
    "\n",
    "    if min_support <= 0.:\n",
    "        raise ValueError('`min_support` must be a positive '\n",
    "                         'number within the interval `(0, 1]`. '\n",
    "                         'Got %s.' % min_support)\n",
    "\n",
    "\n",
    "    if hasattr(df, \"sparse\"):\n",
    "        # DataFrame with SparseArray (pandas >= 0.24)\n",
    "        if df.size == 0:\n",
    "            X = df.values\n",
    "        else:\n",
    "            X = df.sparse.to_coo().tocsc()\n",
    "        is_sparse = True\n",
    "    else:\n",
    "        # dense DataFrame\n",
    "        X = df.values\n",
    "        is_sparse = False\n",
    "    support = _support(X, X.shape[0], is_sparse)\n",
    "    ary_col_idx = np.arange(X.shape[1])\n",
    "    support_dict = {1: support[support >= min_support]}\n",
    "    itemset_dict = {1: ary_col_idx[support >= min_support].reshape(-1, 1)}\n",
    "    max_itemset = 1\n",
    "    rows_count = float(X.shape[0])\n",
    "\n",
    "    all_ones = np.ones((int(rows_count), 1))\n",
    "\n",
    "    while max_itemset and max_itemset < (max_len or float('inf')):\n",
    "        next_max_itemset = max_itemset + 1\n",
    "\n",
    "        # With exceptionally large datasets, the matrix operations can use a\n",
    "        # substantial amount of memory. For low memory applications or large\n",
    "        # datasets, set `low_memory=True` to use a slower but more memory-\n",
    "        # efficient implementation.\n",
    "        if low_memory:\n",
    "            combin = generate_new_combinations_low_memory(\n",
    "                itemset_dict[max_itemset], X, min_support, is_sparse)\n",
    "            # slightly faster than creating an array from a list of tuples\n",
    "            combin = np.fromiter(combin, dtype=int)\n",
    "            combin = combin.reshape(-1, next_max_itemset + 1)\n",
    "\n",
    "            if combin.size == 0:\n",
    "                break\n",
    "            if verbose:\n",
    "                print(\n",
    "                    '\\rProcessing %d combinations | Sampling itemset size %d' %\n",
    "                    (combin.size, next_max_itemset), end=\"\")\n",
    "\n",
    "            itemset_dict[next_max_itemset] = combin[:, 1:]\n",
    "            support_dict[next_max_itemset] = combin[:, 0].astype(float) \\\n",
    "                / rows_count\n",
    "            max_itemset = next_max_itemset\n",
    "        else:\n",
    "            # conver from generator to numpy\n",
    "            combin = generate_new_combinations(itemset_dict[max_itemset])\n",
    "            combin = np.fromiter(combin, dtype=int)\n",
    "            combin = combin.reshape(-1, next_max_itemset)\n",
    "\n",
    "            # end generator\n",
    "            if combin.size == 0:\n",
    "                break\n",
    "            if verbose:\n",
    "                print(\n",
    "                    '\\rProcessing %d combinations | Sampling itemset size %d' %\n",
    "                    (combin.size, next_max_itemset), end=\"\")\n",
    "\n",
    "            if is_sparse:\n",
    "                _bools = X[:, combin[:, 0]] == all_ones\n",
    "                for n in range(1, combin.shape[1]):\n",
    "                    _bools = _bools & (X[:, combin[:, n]] == all_ones)\n",
    "            else:\n",
    "                _bools = np.all(X[:, combin], axis=2)\n",
    "\n",
    "            support = _support(np.array(_bools), rows_count, is_sparse)\n",
    "\n",
    "            _mask = (support >= min_support).reshape(-1)\n",
    "\n",
    "            if any(_mask):\n",
    "\n",
    "                itemset_dict[next_max_itemset] = np.array(combin[_mask])\n",
    "                support_dict[next_max_itemset] = np.array(support[_mask])\n",
    "                max_itemset = next_max_itemset\n",
    "\n",
    "            else:\n",
    "                # Exit condition\n",
    "                # when there no more itemst\n",
    "                break\n",
    "\n",
    "    all_res = []\n",
    "    for k in sorted(itemset_dict):\n",
    "        support = pd.Series(support_dict[k])\n",
    "        itemsets = pd.Series([frozenset(i) for i in itemset_dict[k]],\n",
    "                             dtype='object')\n",
    "\n",
    "        res = pd.concat((support, itemsets), axis=1)\n",
    "        all_res.append(res)\n",
    "\n",
    "    res_df = pd.concat(all_res)\n",
    "    res_df.columns = ['support', 'itemsets']\n",
    "    if use_colnames:\n",
    "        mapping = {idx: item for idx, item in enumerate(df.columns)}\n",
    "        res_df['itemsets'] = res_df['itemsets'].apply(lambda x: frozenset([\n",
    "                                                      mapping[i] for i in x]))\n",
    "    res_df = res_df.reset_index(drop=True)\n",
    "\n",
    "    if verbose:\n",
    "        print()  # adds newline if verbose counter was used\n",
    "\n",
    "    return res_df\n",
    "\n",
    "apriori(item_sets, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranction Reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>StockCode</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "StockCode  A  B  C  D\n",
       "0          0  1  1  1\n",
       "1          1  0  1  1\n",
       "2          1  1  0  0\n",
       "3          1  1  1  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RC count generation\n",
    "itemset_reductabc, rc_values = npi.count(item_sets.values)\n",
    "itemset_reductabc = pd.DataFrame(itemset_reductabc, columns=item_sets.columns)\n",
    "itemset_reductabc = itemset_reductabc.astype(int)\n",
    "itemset_reductabc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>(B, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>(C, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>(D, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>(C, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>(B, D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>(C, D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>(C, B, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>(C, D, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>(C, B, D)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support   itemsets\n",
       "0         3        (A)\n",
       "1         3        (B)\n",
       "2         3        (C)\n",
       "3         2        (D)\n",
       "4         2     (B, A)\n",
       "5         2     (C, A)\n",
       "6         1     (D, A)\n",
       "7         2     (C, B)\n",
       "8         1     (B, D)\n",
       "9         2     (C, D)\n",
       "10        1  (C, B, A)\n",
       "11        1  (C, D, A)\n",
       "12        1  (C, B, D)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sebastian Raschka 2014-2020\n",
    "# myxtend Machine Learning Library Extensions\n",
    "# Author: Sebastian Raschka <sebastianraschka.com>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fpcommon as fpc\n",
    "\n",
    "# RC count generation\n",
    "itemset_reductabc, rc_values = npi.count(item_sets.values)\n",
    "itemset_reductabc = pd.DataFrame(itemset_reductabc, columns=item_sets.columns)\n",
    "itemset_reductabc = itemset_reductabc.astype(int)\n",
    "\n",
    "\n",
    "def generate_new_combinations(old_combinations):\n",
    "\n",
    "    items_types_in_previous_step = np.unique(old_combinations.flatten())\n",
    "    for old_combination in old_combinations:\n",
    "        max_combination = old_combination[-1]  # get a single item in the last\n",
    "        mask = items_types_in_previous_step > max_combination\n",
    "        valid_items = items_types_in_previous_step[mask]\n",
    "\n",
    "        old_tuple = tuple(old_combination)\n",
    "        for item in valid_items:\n",
    "            yield from old_tuple\n",
    "            yield item\n",
    "\n",
    "\n",
    "def generate_new_combinations_low_memory(old_combinations, X, min_support,\n",
    "                                         is_sparse):\n",
    "\n",
    "    items_types_in_previous_step = np.unique(old_combinations.flatten())\n",
    "    rows_count = X.shape[0]\n",
    "    threshold = min_support * rows_count\n",
    "    for old_combination in old_combinations:\n",
    "        max_combination = old_combination[-1]\n",
    "        mask = items_types_in_previous_step > max_combination\n",
    "        valid_items = items_types_in_previous_step[mask]\n",
    "        old_tuple = tuple(old_combination)\n",
    "        if is_sparse:\n",
    "            mask_rows = X[:, old_tuple].toarray().all(axis=1)\n",
    "            X_cols = X[:, valid_items].toarray()\n",
    "            supports = X_cols[mask_rows].sum(axis=0)\n",
    "        else:\n",
    "            mask_rows = X[:, old_tuple].all(axis=1)\n",
    "            supports = X[mask_rows][:, valid_items].sum(axis=0)\n",
    "        valid_indices = (supports >= threshold).nonzero()[0]\n",
    "        for index in valid_indices:\n",
    "            yield supports[index]\n",
    "            yield from old_tuple\n",
    "            yield valid_items[index]\n",
    "\n",
    "\n",
    "def apriori_tranction_reduction(df, min_support=0.5, use_colnames=False, max_len=None, verbose=0):\n",
    "\n",
    "    def _tranction_reduc_support(k_itemset, rc_values):\n",
    "        return (np.bitwise_and.reduce(k_itemset, axis=2) * rc_values.reshape(-1, 1)).sum(axis=0)\n",
    "\n",
    "    def fre_1_itemset(item, minsupp=0):\n",
    "        rc_of_1_itemset = item.sum(axis=0)\n",
    "        item_index = np.arange(item.shape[1])\n",
    "        return rc_of_1_itemset.values[rc_of_1_itemset.values >= minsupp], item_index[rc_of_1_itemset.values >= minsupp]\n",
    "\n",
    "    if min_support <= 0.:\n",
    "        raise ValueError('`min_support` must be a positive '\n",
    "                         'number within the interval `(0, 1]`. '\n",
    "                         'Got %s.' % min_support)\n",
    "\n",
    "    fpc.valid_input_check(df)\n",
    "\n",
    "    if hasattr(df, \"sparse\"):\n",
    "        # DataFrame with SparseArray (pandas >= 0.24)\n",
    "        if df.size == 0:\n",
    "            X = df.values\n",
    "        else:\n",
    "            X = df.sparse.to_coo().tocsc()\n",
    "    else:\n",
    "        # dense DataFrame\n",
    "        X = df.values\n",
    "\n",
    "    one_itemset, support_one_itemset = fre_1_itemset(df, minsupp=min_support)\n",
    "\n",
    "    support_dict = {1: one_itemset}\n",
    "    itemset_dict = {1: support_one_itemset.reshape(-1, 1)}\n",
    "    max_itemset = 1\n",
    "\n",
    "    while max_itemset and max_itemset < (max_len or float('inf')):\n",
    "\n",
    "        next_max_itemset = max_itemset + 1\n",
    "        # convert from generator to numpy\n",
    "        combin = generate_new_combinations(itemset_dict[max_itemset])\n",
    "        combin = np.fromiter(combin, dtype=int)\n",
    "        combin = combin.reshape(-1, next_max_itemset)\n",
    "\n",
    "        if combin.size == 0:  # No more itemset to generate\n",
    "            break\n",
    "\n",
    "        support = _tranction_reduc_support(X[:, combin], rc_values)\n",
    "        _mask = (support >= min_support).reshape(-1)\n",
    "        if any(_mask):\n",
    "            # this will be generate item those are frequent\n",
    "            itemset_dict[next_max_itemset] = np.array(combin[_mask])\n",
    "            support_dict[next_max_itemset] = np.array(support[_mask])\n",
    "            max_itemset = next_max_itemset\n",
    "        else:\n",
    "            # Exit condition\n",
    "            # when there no more itemst\n",
    "            break\n",
    "\n",
    "    all_res = []\n",
    "    for k in sorted(itemset_dict):\n",
    "        support = pd.Series(support_dict[k])\n",
    "        itemsets = pd.Series([frozenset(i) for i in itemset_dict[k]],\n",
    "                             dtype='object')\n",
    "        res = pd.concat((support, itemsets), axis=1)\n",
    "        all_res.append(res)\n",
    "\n",
    "    res_df = pd.concat(all_res)\n",
    "    res_df.columns = ['support', 'itemsets']\n",
    "    if use_colnames:\n",
    "        mapping = {idx: item for idx, item in enumerate(df.columns)}\n",
    "        res_df['itemsets'] = res_df['itemsets'].apply(\n",
    "            lambda x: frozenset([mapping[i] for i in x])\n",
    "        )\n",
    "    res_df = res_df.reset_index(drop=True)\n",
    "    return res_df\n",
    "\n",
    "\n",
    "apriori_tranction_reduction(\n",
    "    itemset_reductabc, use_colnames=True, min_support=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Minimum support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_combinations(old_combinations):\n",
    "    items_types_in_previous_step = np.unique(old_combinations.flatten())\n",
    "    for old_combination in old_combinations:\n",
    "        max_combination = old_combination[-1]  # get a single item in the last\n",
    "        mask = items_types_in_previous_step > max_combination\n",
    "        valid_items = items_types_in_previous_step[mask]\n",
    "        old_tuple = tuple(old_combination)\n",
    "        for item in valid_items:\n",
    "\n",
    "            yield from old_tuple\n",
    "            yield item\n",
    "\n",
    "\n",
    "def generate_new_combinations_low_memory(old_combinations, X, min_support,\n",
    "                                         is_sparse):\n",
    "\n",
    "    items_types_in_previous_step = np.unique(old_combinations.flatten())\n",
    "    rows_count = X.shape[0]\n",
    "    threshold = min_support * rows_count\n",
    "    for old_combination in old_combinations:\n",
    "        max_combination = old_combination[-1]\n",
    "        mask = items_types_in_previous_step > max_combination\n",
    "        valid_items = items_types_in_previous_step[mask]\n",
    "        old_tuple = tuple(old_combination)\n",
    "        if is_sparse:\n",
    "            mask_rows = X[:, old_tuple].toarray().all(axis=1)\n",
    "            X_cols = X[:, valid_items].toarray()\n",
    "            supports = X_cols[mask_rows].sum(axis=0)\n",
    "        else:\n",
    "            mask_rows = X[:, old_tuple].all(axis=1)\n",
    "            supports = X[mask_rows][:, valid_items].sum(axis=0)\n",
    "        valid_indices = (supports >= threshold).nonzero()[0]\n",
    "        for index in valid_indices:\n",
    "            yield supports[index]\n",
    "            yield from old_tuple\n",
    "            yield valid_items[index]\n",
    "\n",
    "\n",
    "def actual_apriori(df, min_support=0, use_colnames=False, max_len=None, verbose=0,\n",
    "            low_memory=False):\n",
    "\n",
    "    def _support(_x, _n_rows, _is_sparse):\n",
    "\n",
    "        out = (np.sum(_x, axis=0) / _n_rows)\n",
    "        return np.array(out).reshape(-1)\n",
    "\n",
    "    if hasattr(df, \"sparse\"):\n",
    "        # DataFrame with SparseArray (pandas >= 0.24)\n",
    "        if df.size == 0:\n",
    "            X = df.values\n",
    "        else:\n",
    "            X = df.sparse.to_coo().tocsc()\n",
    "        is_sparse = True\n",
    "    else:\n",
    "        # dense DataFrame\n",
    "        X = df.values\n",
    "        is_sparse = False\n",
    "    support = _support(X, X.shape[0], is_sparse)\n",
    "    ary_col_idx = np.arange(X.shape[1])\n",
    "    support_dict = {1: support[support > min_support]}\n",
    "    itemset_dict = {1: ary_col_idx[support > min_support].reshape(-1, 1)}\n",
    "    max_itemset = 1\n",
    "    rows_count = float(X.shape[0])\n",
    "\n",
    "    all_ones = np.ones((int(rows_count), 1))\n",
    "\n",
    "    while max_itemset and max_itemset < (max_len or float('inf')):\n",
    "        next_max_itemset = max_itemset + 1\n",
    "\n",
    "        # With exceptionally large datasets, the matrix operations can use a\n",
    "        # substantial amount of memory. For low memory applications or large\n",
    "        # datasets, set `low_memory=True` to use a slower but more memory-\n",
    "        # efficient implementation.\n",
    "        if low_memory:\n",
    "            combin = generate_new_combinations_low_memory(\n",
    "                itemset_dict[max_itemset], X, min_support, is_sparse)\n",
    "            # slightly faster than creating an array from a list of tuples\n",
    "            combin = np.fromiter(combin, dtype=int)\n",
    "            combin = combin.reshape(-1, next_max_itemset + 1)\n",
    "\n",
    "            if combin.size == 0:\n",
    "                break\n",
    "            if verbose:\n",
    "                print(\n",
    "                    '\\rProcessing %d combinations | Sampling itemset size %d' %\n",
    "                    (combin.size, next_max_itemset), end=\"\")\n",
    "\n",
    "            itemset_dict[next_max_itemset] = combin[:, 1:]\n",
    "            support_dict[next_max_itemset] = combin[:, 0].astype(float) \\\n",
    "                / rows_count\n",
    "            max_itemset = next_max_itemset\n",
    "        else:\n",
    "            # conver from generator to numpy\n",
    "            combin = generate_new_combinations(itemset_dict[max_itemset])\n",
    "            combin = np.fromiter(combin, dtype=int)\n",
    "            combin = combin.reshape(-1, next_max_itemset)\n",
    "\n",
    "            # end generator\n",
    "            if combin.size == 0:\n",
    "                break\n",
    "            if verbose:\n",
    "                print(\n",
    "                    '\\rProcessing %d combinations | Sampling itemset size %d' %\n",
    "                    (combin.size, next_max_itemset), end=\"\")\n",
    "\n",
    "            if is_sparse:\n",
    "                _bools = X[:, combin[:, 0]] == all_ones\n",
    "                for n in range(1, combin.shape[1]):\n",
    "                    _bools = _bools & (X[:, combin[:, n]] == all_ones)\n",
    "            else:\n",
    "                _bools = np.all(X[:, combin], axis=2)\n",
    "\n",
    "            support = _support(np.array(_bools), rows_count, is_sparse)\n",
    "\n",
    "            _mask = (support > min_support).reshape(-1)\n",
    "\n",
    "            if any(_mask):\n",
    "                itemset_dict[next_max_itemset] = np.array(combin[_mask])\n",
    "                support_dict[next_max_itemset] = np.array(support[_mask])\n",
    "                max_itemset = next_max_itemset\n",
    "            else:\n",
    "                # Exit condition\n",
    "                # when there no more itemst\n",
    "                break\n",
    "\n",
    "    all_res = []\n",
    "    for k in sorted(itemset_dict):\n",
    "        support = pd.Series(support_dict[k])\n",
    "        itemsets = pd.Series([frozenset(i) for i in itemset_dict[k]],\n",
    "                             dtype='object')\n",
    "        res = pd.concat((support, itemsets), axis=1)\n",
    "        all_res.append(res)\n",
    "\n",
    "    res_df = pd.concat(all_res)\n",
    "    res_df.columns = ['support', 'itemsets']\n",
    "    if use_colnames:\n",
    "        mapping = {idx: item for idx, item in enumerate(df.columns)}\n",
    "        res_df['itemsets'] = res_df['itemsets'].apply(lambda x: frozenset([\n",
    "                                                      mapping[i] for i in x]))\n",
    "    res_df = res_df.reset_index(drop=True)\n",
    "\n",
    "    if verbose:\n",
    "        print()  # adds newline if verbose counter was used\n",
    "\n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(B, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(D, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(B, D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(C, D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(C, B, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(C, D, A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.25</td>\n",
       "      <td>(C, B, D)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support   itemsets\n",
       "0      0.75        (A)\n",
       "1      0.75        (B)\n",
       "2      0.75        (C)\n",
       "3      0.50        (D)\n",
       "4      0.50     (B, A)\n",
       "5      0.50     (C, A)\n",
       "6      0.25     (D, A)\n",
       "7      0.50     (C, B)\n",
       "8      0.25     (B, D)\n",
       "9      0.50     (C, D)\n",
       "10     0.25  (C, B, A)\n",
       "11     0.25  (C, D, A)\n",
       "12     0.25  (C, B, D)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frieq_itemset = actual_apriori(item_sets, use_colnames=True)\n",
    "frieq_itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lean(support_count_i_itemset, M, avg):\n",
    "    less_than_avg = []\n",
    "    greater_than_avg = []\n",
    "    for j in support_count_i_itemset:\n",
    "        if j < avg:\n",
    "            less_than_avg.append(1)\n",
    "        elif j > avg:\n",
    "            greater_than_avg.append(1)\n",
    "    # print(f\"Less avg {less_than_avg}\")\n",
    "    # print(f\"Greater avg {greater_than_avg}\")\n",
    "    return (sum(less_than_avg) - sum(greater_than_avg)) / M\n",
    "\n",
    "\n",
    "def actual_min(r_min, min_supp, max_min, n=1):\n",
    "    a_n = pow(min_supp, n)\n",
    "    b_n = pow(max_min, n)\n",
    "    x_n = (r_min - (a_n / (a_n - b_n))) * (b_n - a_n)\n",
    "    return x_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frieq_itemset = actual_apriori(item_sets, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "supports = frieq_itemset['support']\n",
    "a, b = supports.min(), supports.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear strategy : 0.625\n",
      "Polynomial strategy : 0.3203125\n"
     ]
    }
   ],
   "source": [
    "print(f\"Linear strategy : {actual_min(r_min=0.75, min_supp=a, max_min=b,)}\")\n",
    "print(\n",
    "    f\"Polynomial strategy : {actual_min(r_min=0.75, min_supp=a, max_min=b,n=3)}\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
